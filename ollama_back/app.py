from flask import Flask, request, jsonify
import requests
import sys
from flask_cors import CORS
import torch
from flask_pymongo import PyMongo
from langchain.chains import RetrievalQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Qdrant
from langchain.llms.base import LLM
from qdrant_client import QdrantClient
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from werkzeug.utils import secure_filename
import os

uploaded_pdfs = []  # ğŸ“Œ ì—…ë¡œë“œëœ PDF ëª©ë¡ ì €ì¥
UPLOAD_FOLDER = '/tmp'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# OpenAI API í‚¤ ì„¤ì • (ë³¸ì¸ì˜ API í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”)
os.environ["OPENAI_API_KEY"] = "openai-api-key"

app = Flask(__name__)
CORS(app, supports_credentials=True, origins=["http://172.21.166.164:3000"])
qdrant_client = QdrantClient(url="http://172.21.166.164:6333")
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
sys.stdout.reconfigure(encoding='utf-8')

SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•˜ì„¸ìš”. "
    "ì •ë³´ê°€ ì—†ìœ¼ë©´ 'ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”. "
    "í•œê¸€ë¡œ ë‹µë³€í•˜ë˜, ê¸°ìˆ  ìš©ì–´ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
)

class OllamaLLM(LLM):
    @property
    def _llm_type(self) -> str:
        return "ollama"

    def _call(self, prompt: str, stop=None) -> str:
        url = "http://host.docker.internal:11434/v1/chat/completions"
        headers = {"Content-Type": "application/json"}
        data = {
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            "model": "exaone3.5:latest"
        }

        response = requests.post(url, json=data, headers=headers)
        response.raise_for_status()

        result = response.json()
        return result.get('choices', [{}])[0].get('message', {}).get('content', 'ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')


def call_langchain_with_rag(question):
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
    qdrant_client = QdrantClient(url="http://172.21.166.164:6333")

    collections = qdrant_client.get_collections().collections
    if "papers" not in [collection.name for collection in collections]:
        print("[INFO] 'papers' ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        qdrant_client.create_collection(
            collection_name="papers",
            vectors_config={"size": 1536, "distance": "Cosine"}
        )
        
    qdrant = Qdrant(
        client=qdrant_client,
        collection_name="papers",
        embedding_function=embeddings.embed_query
    )

    retriever = qdrant.as_retriever(search_kwargs={"k": 5})

    qa_chain = RetrievalQA.from_chain_type(
        llm=OllamaLLM(),
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True  # ê²°ê³¼ì— source_documents í¬í•¨
    )

    response = qa_chain({"query": question})  # invoke() ëŒ€ì‹  ì´ë ‡ê²Œ ë³€ê²½
    answer = response["result"]  # 'result' í‚¤ì—ì„œ ë‹µë³€ë§Œ ì¶”ì¶œ
    return answer

@app.route('/upload_pdf', methods=['POST'])
def upload_pdf():
    try:
        print("[INFO] ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­ ìˆ˜ì‹ ë¨.")

        if 'file' not in request.files:
            print("[ERROR] âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        file = request.files['file']
        if file.filename == '':
            print("[ERROR] âŒ íŒŒì¼ëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return jsonify({"error": "íŒŒì¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”."}), 400

        filename = secure_filename(file.filename)
        save_path = os.path.join(UPLOAD_FOLDER, filename)
        file.save(save_path)
        print(f"[INFO] âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")

        # ğŸ“Œ 'pdf_files' ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„± (íŒŒì¼ëª…ë§Œ ì €ì¥)
        collections = qdrant_client.get_collections().collections
        if "pdf_files" not in [collection.name for collection in collections]:
            print("[INFO] 'pdf_files' ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            qdrant_client.create_collection(
                collection_name="pdf_files",
                vectors_config={"size": 1, "distance": "Cosine"}  # âœ… íŒŒì¼ëª…ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ìµœì†Œ ë²¡í„° ì„¤ì • í•„ìš”
            )

        # ğŸ“Œ 'pdf_files' ì»¬ë ‰ì…˜ì— íŒŒì¼ëª… ì €ì¥
        qdrant_client.upsert(
            collection_name="pdf_files",
            points=[
                {
                    "id": hash(filename),  # IDë¥¼ í•´ì‹œ ê°’ìœ¼ë¡œ ì €ì¥
                    "vector": [0.0],  # âœ… ìµœì†Œ ë²¡í„° í•„ìš” (Qdrant ì œí•œ)
                    "payload": {"filename": file.filename}
                }
            ]
        )
        print(f"[INFO] ğŸ“ '{filename}' íŒŒì¼ëª…ì´ pdf_files ì»¬ë ‰ì…˜ì— ì €ì¥ë¨.")

        # PDF ì„ë² ë”© ë° "papers" ì»¬ë ‰ì…˜ ì €ì¥
        loader = PyPDFLoader(save_path)
        documents = loader.load()
        print(f"[INFO] ğŸ“– PDF ë¡œë“œ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(documents)
        print(f"[INFO] âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ: {len(texts)}ê°œ ì²­í¬")

        # ğŸ“Œ 'papers' ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„± (PDF ë‚´ìš© ì €ì¥ìš©)
        collections = qdrant_client.get_collections().collections
        if "papers" not in [collection.name for collection in collections]:
            print("[INFO] 'papers' ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            qdrant_client.create_collection(
                collection_name="papers",
                vectors_config={"size": 1536, "distance": "Cosine"}  # âœ… PDF ì„ë² ë”© ì €ì¥ìš©
            )

        # PDF ë‚´ìš© ì„ë² ë”© í›„ ì €ì¥
        qdrant = Qdrant(client=qdrant_client, collection_name="papers", embedding_function=embeddings.embed_query)
        qdrant.add_documents(texts)
        print("[INFO] âœ… ë¬¸ì„œ ì„ë² ë”© ì €ì¥ ì™„ë£Œ")

        os.remove(save_path)
        print("[INFO] ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")

        return jsonify({"message": "PDF ì—…ë¡œë“œ ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."})

    except Exception as e:
        print(f"[ERROR] ğŸš¨ ì—…ë¡œë“œ ë° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": "ì„œë²„ì—ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500

# ğŸ“Œ ì¶”ê°€: 'pdf_files' ì»¬ë ‰ì…˜ì—ì„œ ì—…ë¡œë“œëœ PDF ëª©ë¡ ë°˜í™˜
@app.route('/get_uploaded_pdfs', methods=['GET'])
def get_uploaded_pdfs():
    qdrant_client = QdrantClient(url="http://172.21.166.164:6333")
    try:
        print("[INFO] ğŸ“œ ì—…ë¡œë“œëœ PDF ëª©ë¡ ìš”ì²­ ìˆ˜ì‹ ë¨.")
        collections = qdrant_client.get_collections().collections
        if "pdf_files" not in [collection.name for collection in collections]:
            return jsonify({"pdfs": []})  # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

        response = qdrant_client.scroll(
            collection_name="pdf_files",
            limit=100
        )

        pdf_list = [item.payload["filename"] for item in response[0]]
        print(f"[INFO] ğŸ“‚ í˜„ì¬ ì—…ë¡œë“œëœ PDF ëª©ë¡: {pdf_list}")
        return jsonify({"pdfs": pdf_list})

    except Exception as e:
        print(f"[ERROR] ğŸš¨ PDF ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
        return jsonify({"error": "ì„œë²„ì—ì„œ PDF ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "details": str(e)}), 500


@app.route('/ask', methods=['POST'])
def ask():
    data = request.get_json()
    question = data.get('question', '')
    rag_active = data.get('rag_active', True)  # í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° ì „ë‹¬ë°›ìŒ

    print(f"[DEBUG] ì§ˆë¬¸: {question}, RAG í™œì„±í™” ì—¬ë¶€: {rag_active}")

    if not question:
        return jsonify({"error": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

    if rag_active:
        print("[INFO] RAG í™œì„±í™”ë¨: LangChainì„ í†µí•´ Ollama í˜¸ì¶œ")
        answer = call_langchain_with_rag(question)
    else:
        print("[INFO] RAG ë¹„í™œì„±í™”ë¨: Ollama ì§ì ‘ í˜¸ì¶œ")
        llm = OllamaLLM()
        answer = llm._call(question)  # ì§ì ‘ í´ë˜ìŠ¤ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
    print(f"[SUCCESS] ë‹µë³€ ìƒì„± ì™„ë£Œ: {answer}")
    return jsonify({"answer_langchain": answer})

if __name__ == "__main__":
    print("[INFO] ğŸš€ ë°±ì—”ë“œ ì„œë²„ ì‹œì‘ ì¤‘...")
    app.run(debug=True, host='0.0.0.0', port=5000)